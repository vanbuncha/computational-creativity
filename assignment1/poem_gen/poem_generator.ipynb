{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install numpy pandas tensorflow nltk requests beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TZoLb0n64Wi",
        "outputId": "d84515a7-f063-47ac-a913-837d3ef33a8a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers torch datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUTF3CpO7a3D",
        "outputId": "9512b740-4eb0-4bfd-8376-9382345db960"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.8)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU-iTnhD6100",
        "outputId": "91ca30a9-b492-413b-9677-fe36621283ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments, TextDataset, DataCollatorForLanguageModeling\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the cleaned combined dataset\n",
        "df = pd.read_csv('/content/all_poets_cleaned_poems.csv')\n",
        "\n",
        "# Combine all poems into a single string with each poem separated by a unique token\n",
        "all_text = \"<|endoftext|>\".join(df['Cleaned_Content'].astype(str).tolist())\n",
        "\n",
        "# Save the formatted text file\n",
        "with open(\"poetry_finetune_data.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(all_text)\n",
        "\n",
        "print(\"Poetry data prepared and saved as 'poetry_finetune_data.txt'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euRLkRiw6_ls",
        "outputId": "c5222746-44f2-43bb-ecaf-991faed7dad2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Poetry data prepared and saved as 'poetry_finetune_data.txt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the cleaned dataset\n",
        "all_poems = pd.read_csv('/content/all_poets_cleaned_poems.csv')\n",
        "\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(all_poems['Cleaned_Content'])\n",
        "\n",
        "# Convert text to sequences of integers\n",
        "sequences = tokenizer.texts_to_sequences(all_poems['Cleaned_Content'])\n",
        "\n",
        "# Save the tokenizer\n",
        "import pickle\n",
        "with open('poetry_tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "print(\"Tokenization complete. Tokenizer saved as 'poetry_tokenizer.pkl'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfeQ0rCZ97rc",
        "outputId": "14d8c0e4-969e-4727-fe86-072d9a3e7eb8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization complete. Tokenizer saved as 'poetry_tokenizer.pkl'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained GPT-2 model and tokenizer\n",
        "model_name = \"gpt2\"  # You can use \"gpt2-medium\" or \"gpt2-large\" for larger models\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Resize the token embeddings to accommodate new tokens if needed\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Load the dataset for GPT-2 fine-tuning\n",
        "def load_dataset(file_path, tokenizer, block_size=128):\n",
        "    dataset = TextDataset(\n",
        "        tokenizer=tokenizer,\n",
        "        file_path=file_path,\n",
        "        block_size=block_size\n",
        "    )\n",
        "    return dataset\n",
        "\n",
        "# Create a data collator that dynamically pads inputs and labels\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False,  # mlm=False means we are not using masked language modeling\n",
        ")\n",
        "\n",
        "# Prepare the dataset and tokenizer\n",
        "train_dataset = load_dataset(\"poetry_finetune_data.txt\", tokenizer)\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2_poetry_model\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=15,  # Adjust the number of epochs based on performance\n",
        "    per_device_train_batch_size=2,  # Reduce if running out of memory\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        ")\n",
        "\n",
        "# Fine-tune the GPT-2 model\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model and tokenizer\n",
        "trainer.save_model(\"/content/fine_tuned_model\")  # Saves model weights and config files\n",
        "tokenizer.save_pretrained(\"/content/tokenizer\")  # Save tokenizer files\n",
        "\n",
        "print(\"Done\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "CWpmImGQ7EOU",
        "outputId": "9eef2bfa-3bc1-45dd-b924-481f3fdc3e2d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5460' max='5460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5460/5460 12:05, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>5.056100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>4.565700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>4.118600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>3.772300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>3.482300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>3.192900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>2.953600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>2.785100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>2.612800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>2.520900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model = GPT2LMHeadModel.from_pretrained(\"/content/fine_tuned_model\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"/content/tokenizer\")\n",
        "\n",
        "# Define the seed text\n",
        "seed_text = \"I never asked for much\"\n",
        "\n",
        "# Encode the input text and set up attention mask\n",
        "input_ids = tokenizer.encode(seed_text, return_tensors='pt')\n",
        "attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n",
        "\n",
        "# number of poems to generate\n",
        "num_poems = 20\n",
        "\n",
        "# Generate  poems\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    attention_mask=attention_mask,  # Explicitly set the attention mask\n",
        "    max_length=150,  # Increase the max length to encourage longer output\n",
        "    min_length=50,  # Set a minimum length to avoid abrupt endings\n",
        "    temperature=0.7,  # Control randomness: lower = less random, higher = more creative\n",
        "    top_k=50,  # Limit the sampling pool to top 50 words for coherence\n",
        "    top_p=0.95,  # Use nucleus sampling for more flexible outputs\n",
        "    repetition_penalty=1.2,  # Penalty for repeating words or phrases\n",
        "    pad_token_id=tokenizer.eos_token_id,  # Use eos_token_id as the pad token\n",
        "    eos_token_id=tokenizer.eos_token_id,  # Set the end-of-sequence token ID\n",
        "    no_repeat_ngram_size=2,  # Prevent repeating bigrams\n",
        "    do_sample=True,  # Enable sampling\n",
        "    num_return_sequences=num_poems  # Set the number of poems to generate\n",
        ")\n",
        "\n",
        "# Decode and display each generated poem\n",
        "for i, poem in enumerate(output):\n",
        "    generated_poem = tokenizer.decode(poem, skip_special_tokens=True)\n",
        "    print(f\"Generated Poem {i + 1}:\\n{generated_poem}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l13MjFunDm1e",
        "outputId": "71246435-486b-4621-8ade-f0ddb05a676f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Poem 1:\n",
            "I never asked for much in return from them but they gave me what was left of my old men and i found new ones more intelligent than myself so we went to bed together thinking about the whole business its all come true lets face it if you dont mind a little bit extra motivation maybe though whats with your big flat head like that some women wont want that then there might be problems im sure hes just as guilty of being an ass too selfish sometimes even selfish not wanting everything at once doesnt he realize thats his own reward surely better things have been faring well enough id buy him coffee now get out of here do something else\n",
            "\n",
            "Generated Poem 2:\n",
            "I never asked for much from you i was young and ignorant of everything the world seemed full only to me a desert of flowers bloomed like roses all afternoon long sun sat down in my room listening music on tv watching cats playing dropped dead sounds then suddenly stars appeared out thru space that didnt seem anywhere else it was dark inside my window i could hear birds singing somewhere there were no walls or pets at play now im too old maybe even guilty maybe not but still some things dont change when you grow up poor an idiot a bum a drunk driving under red lights\n",
            "\n",
            "Generated Poem 3:\n",
            "I never asked for much money and when i got it my father beat me off telling me how youre a poet there was no way im going to make any kind of living because theres nothing in life that can compare with being poor then suddenly he grabbed another man by his belt and started beating him on top of himself all over again but somehow someway thats not right id like to have your poetry thrown out so bad at me now anyway\n",
            "\n",
            "Generated Poem 4:\n",
            "I never asked for much love and i was afraid it would not happen sometimes but theres a reason why im here all day monday mornings poetry readings omaha hamsun reading joe ohara oki nozawa musa akira tomohiro katsuyama on naruhiko japanese paleo sato shih tarchen yeshiva hairti roshi wakishin sen bai at am in australia noon tea with alan marchetti singing lindbergh poet dylan madsen telling his stories about cities and cars as well as poems by other artists who were there too just to get some of that stuff from me\n",
            "\n",
            "Generated Poem 5:\n",
            "I never asked for much love or money the maids seemed awfully nice i should have gotten more from her and when she left my room it was gone forever after but now at work one of our new co-workers came up to me with a demand which is that we all sit down together in the living table next month there will be another shift so dont expect too many marvelous things like flowers or great music its always been fun keep your eyes open let em go\n",
            "\n",
            "Generated Poem 6:\n",
            "I never asked for much from you i loved the idea of someone else with whom to store their possessions my own life was built upon a foundation of love that held no watercolor tricks beauty did not lie and still does when it rains henry sticks her in me she shrieks\n",
            "\n",
            "Generated Poem 7:\n",
            "I never asked for much from him and he sat idk what i wanted but im glad now thats all there is to say about my lonely young self dont get me wrong its nice when youre alone sometimes hes a bit selfish not always the best time of year to be out in the open with your family doesnt hurt very little if its just us being ourselves we cant take it anymore even at night ill fight that off next door maybe\n",
            "\n",
            "Generated Poem 8:\n",
            "I never asked for much and you always felt sad when people said that i was fat they were lying because im thin ill kill them all but me or somebody else if it comes to that there is no getting around being a bum my love of the world just cant make up his mind be mad dont get rich quick death everybodys whore nothings beautiful enough thats why its so hard wont fix anything whats wrong with your bum lonely like china what do you expect from us little fellows who have problems everything falls apart stamps paychecks nobody ever dies young without hope nothing lasts forever poor and sick nobody even bothers to visit once in awhile dying old how did we come making millions as artists starving poverty has killed our fathers children sons brothers sisters mother no more\n",
            "\n",
            "Generated Poem 9:\n",
            "I never asked for much in return and i am glad that my father died when all was said to have paid me well even if it meant writing a check which is what he did so lovely wives but you know those are not the only ones who suffer because their fathers didnt like them\n",
            "\n",
            "Generated Poem 10:\n",
            "I never asked for much love or favors and i always felt lonely everywhere im from so many different walks of life but one thing stands out about me all the things that made me feel loved were those loves which didnt make any difference except maybe a little bit of hate sometimes even hatred\n",
            "\n",
            "Generated Poem 11:\n",
            "I never asked for much from you i am glad to have met a man like myself who can match my needs without resorting even to sexual innuendos and he is handsome with large dark eyes too big for me therefore dont feel bad if im not looking then what should i expect in return when the money comes my father doesnt pay his college tuitions arent enough men do not want their wives or children out of them they also must wait decades before making any real judgments about whether it is worth living or death its only now that our society has caught wind how vicious this may be somehow so anonymous\n",
            "\n",
            "Generated Poem 12:\n",
            "I never asked for much love in return i told him you might as well have been murdered because of me he said that was the way it was and then when my brother got home from work after his shift we sat outside drinking beer watching tv news while our mothers and fathers played cards with each other there was nothing else to do besides sit down beside each others elbows on either side eating or listening a song thats not right daddy its true im sorry if your life isnt mine id go out into it enjoy yourself please dont ever expect anything at all\n",
            "\n",
            "Generated Poem 13:\n",
            "I never asked for much from you i was too clever to talk and nobody ever called me back even when we were fighting in the betting windows inside each other there was always that old guy sitting next door who just wanted to get out of here so he could buy cigarettes while my wife and son watched over us\n",
            "\n",
            "Generated Poem 14:\n",
            "I never asked for much love and when i did ask for it my god didnt even know how to calculate thank you thats why im here so sad but yeah its true man everybodys should tell their husbands theyve got to be strong some men do get emotional sometimes only a little bit of love is enough most women dont want to hurt or kill just as ill not always have that woman with the money then there are those who either chase after or persuade by words relationships broken homes lost loves left behind whats more attractive than children alone time wasted trying hard doesnt work out great works done well if someone tells you no go easy life stay young suicide beware old age yes death chances poor upbringing alcoholism abuse mind change all this stuff while drunk on drugs past good times\n",
            "\n",
            "Generated Poem 15:\n",
            "I never asked for much money and all i got was letters from editors in the upper echelons of america complaining about ants and bees and other trivial concerns and my constant companion had to be fed by a circus monkey only one month after publishing she died suddenly of alcoholism aged just thirty eight her most notable works were simply ignored or destroyed entirely except perhaps this little poem\n",
            "\n",
            "Generated Poem 16:\n",
            "I never asked for much love and i was always told to be kind but when you are young its very lonely being pushed around like that even in the prosaic situations sometimes it is better to stay put than to leave no matter what happens may be years or decades maybe centuries too late just as most of us think thats enough if we dont get along well\n",
            "\n",
            "Generated Poem 17:\n",
            "I never asked for much love from anybody and i am glad to have met someone who can help me with my difficult days now im just too happy about it all no need begging or promises of anything at present ill carry on living as if nothing happened everythings fine\n",
            "\n",
            "Generated Poem 18:\n",
            "I never asked for much money when they first started making me ill look worse i was just too young and ashamed to work again like that old balding dame thats why im so pissed at you all these men with huge egos who treat women badly then complain about nothing its the same way as breathing in your own nostrils whats wrong with us children if we can blame somebody else sometimes it is better not think of anyone but yourself\n",
            "\n",
            "Generated Poem 19:\n",
            "I never asked for much in return but only because i really wanted to get out of bed every night and into the street no home ever came true im a failure on both counts my paintings look better when they are done well enough with bodies eyes moving about id smile at them tho ill always have birthday cakes\n",
            "\n",
            "Generated Poem 20:\n",
            "I never asked for much love from you i only saw the sunlight shine through my armor of steel and iron and when i got home it was still there so sad then to have lost a friend like that but somehow in spite very little love me or anyone\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !zip -r poem_generator /content\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3mP1Bg4LI_4",
        "outputId": "f8841273-5d0a-49e0-f2b3-e1e0458c439f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/ (stored 0%)\n",
            "  adding: content/.config/ (stored 0%)\n",
            "  adding: content/.config/default_configs.db (deflated 98%)\n",
            "  adding: content/.config/.last_update_check.json (deflated 22%)\n",
            "  adding: content/.config/active_config (stored 0%)\n",
            "  adding: content/.config/.last_opt_in_prompt.yaml (stored 0%)\n",
            "  adding: content/.config/logs/ (stored 0%)\n",
            "  adding: content/.config/logs/2024.10.03/ (stored 0%)\n",
            "  adding: content/.config/logs/2024.10.03/13.24.37.784488.log (deflated 57%)\n",
            "  adding: content/.config/logs/2024.10.03/13.24.26.842428.log (deflated 85%)\n",
            "  adding: content/.config/logs/2024.10.03/13.23.55.907439.log (deflated 93%)\n",
            "  adding: content/.config/logs/2024.10.03/13.24.27.913856.log (deflated 58%)\n",
            "  adding: content/.config/logs/2024.10.03/13.24.16.945701.log (deflated 58%)\n",
            "  adding: content/.config/logs/2024.10.03/13.24.38.390038.log (deflated 56%)\n",
            "  adding: content/.config/configurations/ (stored 0%)\n",
            "  adding: content/.config/configurations/config_default (deflated 15%)\n",
            "  adding: content/.config/hidden_gcloud_config_universe_descriptor_data_cache_configs.db (deflated 97%)\n",
            "  adding: content/.config/config_sentinel (stored 0%)\n",
            "  adding: content/.config/.last_survey_prompt.yaml (stored 0%)\n",
            "  adding: content/.config/gce (stored 0%)\n",
            "  adding: content/tokenizer/ (stored 0%)\n",
            "  adding: content/tokenizer/tokenizer_config.json (deflated 54%)\n",
            "  adding: content/tokenizer/vocab.json (deflated 68%)\n",
            "  adding: content/tokenizer/merges.txt (deflated 53%)\n",
            "  adding: content/tokenizer/special_tokens_map.json (deflated 74%)\n",
            "  adding: content/all_poets_cleaned_poems.csv (deflated 69%)\n",
            "  adding: content/gpt2_poetry_model/ (stored 0%)\n",
            "  adding: content/gpt2_poetry_model/checkpoint-5460/ (stored 0%)\n",
            "  adding: content/gpt2_poetry_model/checkpoint-5460/optimizer.pt (deflated 8%)\n",
            "  adding: content/gpt2_poetry_model/checkpoint-5460/rng_state.pth (deflated 25%)\n",
            "  adding: content/gpt2_poetry_model/checkpoint-5460/config.json (deflated 52%)\n",
            "  adding: content/gpt2_poetry_model/checkpoint-5460/generation_config.json (deflated 24%)\n",
            "  adding: content/gpt2_poetry_model/checkpoint-5460/trainer_state.json (deflated 69%)\n",
            "  adding: content/gpt2_poetry_model/checkpoint-5460/training_args.bin (deflated 51%)\n",
            "  adding: content/gpt2_poetry_model/checkpoint-5460/scheduler.pt (deflated 56%)\n",
            "  adding: content/gpt2_poetry_model/checkpoint-5460/model.safetensors (deflated 7%)\n",
            "  adding: content/gpt2_poetry_model/checkpoint-5000/ (stored 0%)\n",
            "  adding: content/gpt2_poetry_model/checkpoint-5000/optimizer.pt (deflated 8%)\n",
            "  adding: content/gpt2_poetry_model/checkpoint-5000/rng_state.pth (deflated 25%)\n",
            "  adding: content/gpt2_poetry_model/checkpoint-5000/config.json (deflated 52%)\n",
            "  adding: content/gpt2_poetry_model/checkpoint-5000/generation_config.json (deflated 24%)\n",
            "  adding: content/gpt2_poetry_model/checkpoint-5000/trainer_state.json (deflated 69%)\n",
            "  adding: content/gpt2_poetry_model/checkpoint-5000/training_args.bin (deflated 51%)\n",
            "  adding: content/gpt2_poetry_model/checkpoint-5000/scheduler.pt (deflated 55%)\n",
            "  adding: content/gpt2_poetry_model/checkpoint-5000/model.safetensors (deflated 7%)\n",
            "  adding: content/gpt2_poetry_model/runs/ (stored 0%)\n",
            "  adding: content/gpt2_poetry_model/runs/Oct05_09-51-25_afe29616cd31/ (stored 0%)\n",
            "  adding: content/gpt2_poetry_model/runs/Oct05_09-51-25_afe29616cd31/events.out.tfevents.1728121887.afe29616cd31.251.0 (deflated 61%)\n",
            "  adding: content/fine_tuned_model/ (stored 0%)\n",
            "  adding: content/fine_tuned_model/config.json (deflated 52%)\n",
            "  adding: content/fine_tuned_model/generation_config.json (deflated 24%)\n",
            "  adding: content/fine_tuned_model/training_args.bin (deflated 51%)\n",
            "  adding: content/fine_tuned_model/model.safetensors (deflated 7%)\n",
            "  adding: content/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/poetry_finetune_data.txt (deflated 62%)\n",
            "  adding: content/poetry_tokenizer.pkl (deflated 54%)\n",
            "  adding: content/cached_lm_GPT2Tokenizer_128_poetry_finetune_data.txt (deflated 44%)\n",
            "  adding: content/cached_lm_GPT2Tokenizer_128_poetry_finetune_data.txt.lock (stored 0%)\n",
            "  adding: content/sample_data/ (stored 0%)\n",
            "  adding: content/sample_data/anscombe.json (deflated 83%)\n",
            "  adding: content/sample_data/README.md (deflated 39%)\n",
            "  adding: content/sample_data/california_housing_test.csv (deflated 76%)\n",
            "  adding: content/sample_data/mnist_test.csv (deflated 88%)\n",
            "  adding: content/sample_data/mnist_train_small.csv (deflated 88%)\n",
            "  adding: content/sample_data/california_housing_train.csv (deflated 79%)\n"
          ]
        }
      ]
    }
  ]
}